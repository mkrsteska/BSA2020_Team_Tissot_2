{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "This is basically the same as the project notebook but the models are trained on the full train data and we generate the submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"https://raw.githubusercontent.com/DLaux/BSA2020_Team_Tissot_Project_2/master/data/train.csv\", \n",
    "                          encoding='utf_8', \n",
    "                          dtype = 'unicode',\n",
    "                          parse_dates = True,\n",
    "                          infer_datetime_format = True,\n",
    "                          low_memory=False)\n",
    "\n",
    "df_test = pd.read_csv(\"https://raw.githubusercontent.com/DLaux/BSA2020_Team_Tissot_Project_2/master/data/test.csv\", \n",
    "                          encoding='utf_8', \n",
    "                          dtype = 'unicode',\n",
    "                          parse_dates = True,\n",
    "                          infer_datetime_format = True,\n",
    "                          low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from preprocess_tweets import preprocess_tweet, remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.text = df_train.text.apply(preprocess_tweet).apply(remove_stopwords)\n",
    "df_test.text = df_test.text.apply(preprocess_tweet).apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop([\"target\", \"id\"], axis =1)\n",
    "y = df_train[\"target\"]\n",
    "\n",
    "X_test = df_test.drop([\"id\"], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.keyword = X.keyword.astype(\"str\")\n",
    "X.location = X.location.astype(\"str\")\n",
    "X.text = X.text.astype(\"str\")\n",
    "\n",
    "X_test.keyword = X_test.keyword.astype(\"str\")\n",
    "X_test.location = X_test.location.astype(\"str\")\n",
    "X_test.text = X_test.text.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the target \n",
    "lab_enc = LabelEncoder()\n",
    "encoded_y = lab_enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dtc = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('dtc', DecisionTreeClassifier(random_state=42, max_depth = 85))\n",
    "])\n",
    "\n",
    "keyword_dtc = keyword_dtc.fit(X.keyword, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_abc = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('abc', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "location_abc = location_abc.fit(X.location, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mnb = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "text_mnb = text_mnb.fit(X.text, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_predictions(X_input):\n",
    "    #supress a warning\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    \n",
    "    text_pred = text_mnb.predict_proba(X_input.text)\n",
    "    location_pred = location_abc.predict_proba(X_input.location)\n",
    "    keyword_pred = keyword_dtc.predict_proba(X_input.keyword)\n",
    "\n",
    "    X_input['text_pred'] = text_pred[:,0]\n",
    "    X_input['location_pred'] = location_pred[:,0]\n",
    "    X_input['keyword_pred'] = keyword_pred[:,0] \n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_predictions(X)\n",
    "add_predictions(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_pred</th>\n",
       "      <th>location_pred</th>\n",
       "      <th>keyword_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.212053</td>\n",
       "      <td>0.50024</td>\n",
       "      <td>0.260274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061358</td>\n",
       "      <td>0.50024</td>\n",
       "      <td>0.260274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_pred  location_pred  keyword_pred\n",
       "0   0.212053        0.50024      0.260274\n",
       "1   0.061358        0.50024      0.260274"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[[\"text_pred\", \"location_pred\", \"keyword_pred\"]].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "meta_nusvc = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('nusvc', NuSVC(random_state=42))\n",
    "])\n",
    "\n",
    "meta_nusvc = meta_nusvc.fit(X[[\"text_pred\", \"location_pred\", \"keyword_pred\"]], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = meta_nusvc.predict(X_test[[\"text_pred\", \"location_pred\", \"keyword_pred\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"target\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df_test.drop([\"keyword\", \"location\", \"text\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(r'../data/submission.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
