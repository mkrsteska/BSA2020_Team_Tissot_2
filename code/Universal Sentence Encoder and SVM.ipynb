{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Universal Sentence Encoder and SVM",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPOHPHPxi1cCrE70hllna82",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkrsteska/BSA2020_Team_Tissot_Project_2/blob/master/code/Universal%20Sentence%20Encoder%20and%20SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i0ocepQKDZy",
        "colab_type": "text"
      },
      "source": [
        "**In this notebook we have the model that achieved the best accuracy on Kaggle.**\n",
        "\n",
        "**The other models we have tried are in separate notebooks, that can be found in the GitHub repository.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzVPWO1lgw7N",
        "colab_type": "text"
      },
      "source": [
        "### GitHub repository ###\n",
        "[GitHub](https://github.com/mkrsteska/BSA2020_Team_Tissot_Project_2)\n",
        "\n",
        "### Link to our video ###\n",
        "[Video](https://www.youtube.com/watch?v=WDVuDgq4BTc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE4F7G0RjGlJ",
        "colab_type": "text"
      },
      "source": [
        "### Kaggle Ranking ###\n",
        "![Kaggle ranking](https://raw.githubusercontent.com/mkrsteska/BSA2020_Team_Tissot_Project_2/master/data/Kaggle_ranking.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmCJ_h1CzTsu",
        "colab_type": "code",
        "outputId": "f17e7a2f-d0da-4e5d-ab01-bc191ffdcf35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "from tqdm import tqdm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from preprocess_tweets import preprocess_tweet_use\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrSG4FamGxjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the data \n",
        "df_train = pd.read_csv(\"https://raw.githubusercontent.com/mkrsteska/BSA2020_Team_Tissot_Project_2/master/data/train.csv\")\n",
        "df_train = df_train[[\"text\", \"target\"]]\n",
        "df_test = pd.read_csv(\"https://raw.githubusercontent.com/mkrsteska/BSA2020_Team_Tissot_Project_2/master/data/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAa8NpVcGyDJ",
        "colab_type": "text"
      },
      "source": [
        "### Universal Sentence Encoder \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw5jj8vC0Agt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Universal Sentence Encoder\n",
        "use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "586ee086-58e4-402a-db8e-c839021cf8d0",
        "id": "t-6HVOI5mEBF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Encoding tweets into embedding vectors using universal sentence encoder\n",
        "\n",
        "X_train = []\n",
        "for r in tqdm(df_train.text.values):\n",
        "  emb = use([r])\n",
        "  text_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_train.append(text_emb)\n",
        "  \n",
        "X_train = np.array(X_train)\n",
        "y_train = df_train.target.values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7613/7613 [03:00<00:00, 42.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d56f1163-d9ef-49a1-b490-044d9401c2bd",
        "id": "3DT_1vXrmRUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Encoding tweets into embedding vectors using universal sentence encoder\n",
        "\n",
        "X_test = []\n",
        "for r in tqdm(df_test.text.values):\n",
        "  emb = use([r])\n",
        "  text_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_test.append(text_emb)\n",
        "\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3263/3263 [01:14<00:00, 43.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE6knPM4wroh",
        "colab_type": "code",
        "outputId": "9822a303-8824-4054-e41c-68b33de50dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Parameter estimation using grid search with cross-validation\n",
        "\n",
        "Cs = [1, 1.01, 1.03, 1.05, 1.07, 1.09, 1.1, 1.3, 1.5, 1.7, 1.9, 2]\n",
        "#Cs = [1.070, 1.074, 1.075, 1.1, 1.125]\n",
        "gammas = [2.01, 2.03, 2.05, 2.07, 2.09]\n",
        "#gammas = [2.065, 2.075, 2.08]\n",
        "param_grid = {'C': Cs, 'gamma' : gammas}\n",
        "grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv = 5, n_jobs=8)\n",
        "grid_search.fit(X_train, y_train)\n",
        "grid_search.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1, 'gamma': 2.09}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6ysBzAEPlqxy",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=37)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5SSyfruHSqQ",
        "colab_type": "code",
        "outputId": "5fe28a6a-ee82-410e-c9d6-3a2a91d4f3f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_3 = SVC(kernel='rbf', C=1, gamma=2.09, probability=True)\n",
        "\n",
        "model_3.fit(X_train, y_train)\n",
        "\n",
        "model_3.score(X_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8530183727034121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GDolKjjvHcPx"
      },
      "source": [
        "**Create submission files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK7fRA381iFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = df_test['id'].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG6ttdbWHiBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_3 = model_3.predict(X_test)\n",
        "pd.DataFrame({'id': ids, 'target': predictions_3}).to_csv('14. Submission_SVC.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vstApoz_hHhq",
        "colab_type": "text"
      },
      "source": [
        "### Correct Mislabeled Samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "righH6EThaHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_mislabeled = df_train.groupby(['text']).nunique().sort_values(by='target', ascending=False)\n",
        "df_mislabeled = df_mislabeled[df_mislabeled['target'] > 1]['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDNz2gIohm6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.loc[df_train['text'] == 'like for the music video I want some real action shit like burning buildings and police chases not some weak ben winston shit', 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == 'Hellfire is surrounded by desires so be careful and donÛªt let your desires control you! #Afterlife', 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == 'To fight bioterrorism sir.', 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == '.POTUS #StrategicPatience is a strategy for #Genocide; refugees; IDP Internally displaced people; horror; etc. https://t.co/rqWuoy1fm4', 'target_relabeled'] = 1\n",
        "df_train.loc[df_train['text'] == 'CLEARED:incident with injury:I-495  inner loop Exit 31 - MD 97/Georgia Ave Silver Spring', 'target_relabeled'] = 1\n",
        "df_train.loc[df_train['text'] == '#foodscare #offers2go #NestleIndia slips into loss after #Magginoodle #ban unsafe and hazardous for #humanconsumption', 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == 'In #islam saving a person is equal in reward to saving all humans! Islam is the opposite of terrorism!', 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == 'Who is bringing the tornadoes and floods. Who is bringing the climate change. God is after America He is plaguing her\\n \\n#FARRAKHAN #QUOTE', 'target_relabeled'] = 1\n",
        "df_train.loc[df_train['text'] == 'RT NotExplained: The only known image of infamous hijacker D.B. Cooper. http://t.co/JlzK2HdeTG', 'target_relabeled'] = 1\n",
        "df_train.loc[df_train['text'] == \"Mmmmmm I'm burning.... I'm burning buildings I'm building.... Oooooohhhh oooh ooh...\", 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == \"wowo--=== 12000 Nigerian refugees repatriated from Cameroon\", 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == \"He came to a land which was engulfed in tribal war and turned it into a land of peace i.e. Madinah. #ProphetMuhammad #islam\", 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == \"Hellfire! We donÛªt even want to think about it or mention it so letÛªs not do anything that leads to it #islam!\", 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == \"The Prophet (peace be upon him) said 'Save yourself from Hellfire even if it is by giving half a date in charity.'\", 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == \"Caution: breathing may be hazardous to your health.\", 'target_relabeled'] = 1\n",
        "df_train.loc[df_train['text'] == \"I Pledge Allegiance To The P.O.P.E. And The Burning Buildings of Epic City. ??????\", 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == \"#Allah describes piling up #wealth thinking it would last #forever as the description of the people of #Hellfire in Surah Humaza. #Reflect\", 'target_relabeled'] = 0\n",
        "df_train.loc[df_train['text'] == \"that horrible sinking feeling when youÛªve been at home on your phone for a while and you realise its been on 3G this whole time\", 'target_relabeled'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fko9RAYkG_At",
        "colab_type": "code",
        "outputId": "586ee086-58e4-402a-db8e-c839021cf8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Encoding tweets into embedding vectors using universal sentence encoder\n",
        "\n",
        "X_train = []\n",
        "for r in tqdm(df_train.text.values):\n",
        "  emb = use([r])\n",
        "  text_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_train.append(text_emb)\n",
        "  \n",
        "X_train = np.array(X_train)\n",
        "y_train = df_train.target.values"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7613/7613 [03:00<00:00, 42.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nJ7tvgMHAOc",
        "colab_type": "code",
        "outputId": "d56f1163-d9ef-49a1-b490-044d9401c2bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Encoding tweets into embedding vectors using universal sentence encoder\n",
        "\n",
        "X_test = []\n",
        "for r in tqdm(df_test.text.values):\n",
        "  emb = use([r])\n",
        "  text_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_test.append(text_emb)\n",
        "\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3263/3263 [01:14<00:00, 43.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPv4jlN3HORy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=37)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In7nKfn7inHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6eb4b922-bffc-4af6-aec9-7b54e45bfd07"
      },
      "source": [
        "# After correcting the mislabeled samples\n",
        "model_4 = SVC(kernel='rbf', C=1, gamma=2.09, probability=True)\n",
        "\n",
        "model_4.fit(X_train, y_train)\n",
        "\n",
        "model_4.score(X_val, y_val)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8530183727034121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FcOzwFxxlgte"
      },
      "source": [
        "**Create a submission file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2QClLt8jeuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_4 = model_4.predict(X_test)\n",
        "pd.DataFrame({'id': ids, 'target': predictions_4}).to_csv('15. Submission_SVC.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss875YFxPFBf",
        "colab_type": "text"
      },
      "source": [
        "### Universal Sentence Encoder \n",
        "with preprocessed tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UojP1N650rbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = df_train.text.apply(preprocess_tweet_use)\n",
        "test_text = df_test.text.apply(preprocess_tweet_use)\n",
        "y_train = df_train.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w16TWH8y0krn",
        "colab_type": "code",
        "outputId": "c5306b8c-bc90-44a4-aafe-c0982fb16cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Encoding tweets into embedding vectors using universal sentence encoder\n",
        "\n",
        "X_train = []\n",
        "for r in tqdm(df.text.values):\n",
        "  emb = use([r])\n",
        "  text_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_train.append(text_emb)\n",
        "X_train = np.array(X_train)\n",
        "y_train = df.target.values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7613/7613 [02:13<00:00, 57.17it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLnRPvaz0wxi",
        "colab_type": "code",
        "outputId": "07be1e96-717d-4d43-e525-4fd10a283cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Encoding tweets into embedding vectors using universal sentence encoder\n",
        "\n",
        "X_test = []\n",
        "for r in tqdm(df_test.text.values):\n",
        "  emb = use([r])\n",
        "  text_emb = tf.reshape(emb, [-1]).numpy()\n",
        "  X_test.append(text_emb)\n",
        "\n",
        "X_test = np.array(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3263/3263 [00:55<00:00, 58.81it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fZ36lpv00gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=37)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk_TOCm-zZEg",
        "colab_type": "code",
        "outputId": "1dbf7313-556d-4938-f6bf-011080a05fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = SVC(kernel='rbf', C=1, gamma=2.09, probability=True)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "model.score(X_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8535911602209945"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seOfeO9N1VTc",
        "colab_type": "code",
        "outputId": "4f0ea3a1-2243-4a1e-f0c4-348e78d96ff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_2 = SVC(kernel='rbf', C=1.07, gamma=2.075, probability=True)\n",
        "\n",
        "model_2.fit(X_train, y_train)\n",
        "\n",
        "model_2.score(X_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.850828729281768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7NUMGHn1b-E",
        "colab_type": "text"
      },
      "source": [
        "**Create a submission file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTijOWs71kEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "pd.DataFrame({'id': ids, 'target': predictions}).to_csv('13. Submission_SVC.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ-9-h3u1mKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_2 = model_2.predict(X_test)\n",
        "pd.DataFrame({'id': ids, 'target': predictions_2}).to_csv('8. Submission_SVC.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}