{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkrsteska/BSA2020_Team_Tissot_Project_2/blob/master/code/BERT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wVoD-i_TdpZD"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPnD6pGGOHey",
        "colab_type": "text"
      },
      "source": [
        "## not done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RkbUD1lBddt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bert-for-tf2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F2vmlZmuD3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import bert\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZvQJnDnyFxh",
        "colab_type": "text"
      },
      "source": [
        "#### BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckLHTGCPsvGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\", trainable = True)\n",
        "\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqMnF8BjyH4_",
        "colab_type": "text"
      },
      "source": [
        "#### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7UyVzRB_giic",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(\"https://raw.githubusercontent.com/mkrsteska/BSA2020_Team_Tissot_Project_2/master/data/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xYiaOXXnV8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df_train.text.values\n",
        "y_train = df_train.target.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYw2z4ABzx-c",
        "colab_type": "text"
      },
      "source": [
        "#### BERT encode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ2QU5FyHkpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9DJgpY_IK0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize the tweets\n",
        "tokenized_tweets = [tokenizer.tokenize(tweet) for tweet in X_train]\n",
        "tokenized_tweets = [tweet[:MAX_LEN-2] for tweet in tokenized_tweets]\n",
        "\n",
        "# add special tokens at the beginning and end of each tweet for BERT to work properly\n",
        "tokenized_tweets = [[\"[CLS]\"] + tweet + [\"[SEP]\"] for tweet in tokenized_tweets]\n",
        "\n",
        "# convert the tokens to their index numbers in the BERT vocabulary\n",
        "tokenized_tweets_ids = [tokenizer.convert_tokens_to_ids(tweet) for tweet in tokenized_tweets]\n",
        "\n",
        "# pad the input tokens to max_len\n",
        "all_input_word_ids = [tweet + [0]*(MAX_LEN-len(tweet)) for tweet in tokenized_tweets_ids]\n",
        "# all_input_word_ids = pad_sequences(tokenized_tweets_ids, maxlen=MAX_LEN, dtype=\"long\", padding=\"post\")\n",
        "\n",
        "# 1 - tokenized words, 0 - padded zeros\n",
        "all_masks = [[1] * len(tweet) + [0] * (MAX_LEN - len(tweet)) for tweet in tokenized_tweets]\n",
        "\n",
        "all_segment_ids = [[0] * MAX_LEN for tweet in tokenized_tweets]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmC9aszJK4ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_input_word_ids = np.array(all_input_word_ids)\n",
        "all_masks = np.array(all_masks)\n",
        "all_segment_ids = np.array(all_segment_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tatYh-g4z9Pn",
        "colab_type": "text"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSYcUS5xKFIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_word_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "input_mask = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"input_mask\")\n",
        "segment_ids = Input(shape=(MAX_LEN,), dtype=tf.int32, name=\"segment_ids\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zif78bM7--T_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "out = Dense(1, activation='sigmoid')(sequence_output[:, 0, :])\n",
        "    \n",
        "model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkQlPbOL_EGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ-1vZZr-usx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "6ca7dfdc-ee6e-4657-b777-747cd00abed4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 1024)]       0           keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            1025        tf_op_layer_strided_slice[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 335,142,914\n",
            "Trainable params: 335,142,913\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QJohawCRYPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ee6fe4c0-95a4-496b-f42a-c094baf00446"
      },
      "source": [
        "model.fit(\n",
        "    (all_input_word_ids, all_masks, all_segment_ids), y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=2,\n",
        "    batch_size=4)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1523/1523 [==============================] - 319s 210ms/step - loss: 0.1154 - accuracy: 0.9557 - val_loss: 0.6495 - val_accuracy: 0.8398\n",
            "Epoch 2/2\n",
            "1523/1523 [==============================] - 317s 208ms/step - loss: 0.0840 - accuracy: 0.9690 - val_loss: 0.6518 - val_accuracy: 0.8260\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8132182c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGKlAii-wD5D",
        "colab_type": "text"
      },
      "source": [
        "### Create a submission file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV3NMQ7hwF9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = pd.read_csv(\"https://raw.githubusercontent.com/mkrsteska/BSA2020_Team_Tissot_Project_2/master/data/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHmBEtF7xPbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = df_train.text.values\n",
        "ids = df_test['id'].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q47VIho6wm9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize the tweets\n",
        "tokenized_tweets_test = [tokenizer.tokenize(tweet) for tweet in X_test]\n",
        "tokenized_tweets_test = [tweet[:MAX_LEN-2] for tweet in tokenized_tweets_test]\n",
        "\n",
        "# add special tokens at the beginning and end of each tweet for BERT to work properly\n",
        "tokenized_tweets_test = [[\"[CLS]\"] + tweet + [\"[SEP]\"] for tweet in tokenized_tweets_test]\n",
        "\n",
        "# convert the tokens to their index numbers in the BERT vocabulary\n",
        "tokenized_tweets_ids = [tokenizer.convert_tokens_to_ids(tweet) for tweet in tokenized_tweets_test]\n",
        "\n",
        "# pad the input tokens to max_len\n",
        "all_input_word_ids_test = [tweet + [0]*(MAX_LEN-len(tweet)) for tweet in tokenized_tweets_test]\n",
        "# all_input_word_ids = pad_sequences(tokenized_tweets_ids, maxlen=MAX_LEN, dtype=\"long\", padding=\"post\")\n",
        "\n",
        "# 1 - tokenized words, 0 - padded zeros\n",
        "all_masks_test = [[1] * len(tweet) + [0] * (MAX_LEN - len(tweet)) for tweet in tokenized_tweets_test]\n",
        "\n",
        "all_segment_ids_test = [[0] * MAX_LEN for tweet in tokenized_tweets_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts-Yz4NTxW7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_input_word_ids_test = np.array(all_input_word_ids_test)\n",
        "all_masks_test = np.array(all_masks_test)\n",
        "all_segment_ids_test = np.array(all_segment_ids_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0N5wuuPxkxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict((all_input_word_ids_test, all_masks_test, all_segment_ids_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHK6yl0xyS4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame({'id': ids, 'target': test_predict}).to_csv('12. Submission_BERT_2.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}